#%% [markdown]
## importando los modulos requeridos
#%%
import tensorflow as tf
from tensorflow import keras
print(tf.__version__)

import numpy as np
import pandas as pd
#%% [markdown]
## Se lee el data set
data_1=pd.read_excel(r'C:\Users\Joel\Downloads\Machine learning for bussines intelligence\Tarea_1\dataset1.xlsx')
data_1.head(10)
#%%

from sklearn.preprocessing import LabelEncoder , StandardScaler , OneHotEncoder
#Label enconder para agregar etiquetas numericas a la columna categorica crr_Nom
categorical_features_mask=data_1.dtypes==object
categorical_cols=data_1.columns[categorical_features_mask].tolist()
le=LabelEncoder()
data_1[categorical_cols] = data_1[categorical_cols].apply(lambda col:le.fit_transform(col))
keys=le.classes_
#Se desordena las filas de la matriz
data_1=data_1.sample(frac=1)

data_x=data_1.loc[:,:'MUNICIPAL']
y=data_1['cluster']


#Se suavizan (normalizan) los valores de x con StandarScaler
scaler = StandardScaler()
x=scaler.fit_transform(data_x)

#Onehotencoder para y
y=np.array(y)
y=y.reshape(-1, 1)
oneHot = OneHotEncoder() 
oneHot.fit(y) 
y = oneHot.transform(y).toarray() 

#Tama√±o de train y test
data_size = data_1.shape[0]
train_pct = 0.8
train_size = int(data_size * train_pct)

x_train, y_train = x[:train_size], y[:train_size] 
#x_train e y_train son  numpy.array
x_test, y_test = x[train_size:], y[train_size:] 
   #x_test and y_test are  numpy.arrays  
#%% [markdown]
# Se utiliza queras para  establecer la red de 1 capa
#Una unicacapade 4 nodos, donde aprendera los 4 cluster distintos

#%%
model = keras.Sequential([
    keras.layers.Dense(4, activation='softmax')
])

model.compile(
    #loss='mse', # keras.losses.mean_squared_error
    #optimizer=keras.optimizers.SGD(lr=0.2),
    loss='categorical_crossentropy',
    optimizer='rmsprop',
    metrics=['accuracy']
)

model.fit(x_train, y_train, epochs=10)
model.summary()

test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)
print('\nTest accuracy:', test_acc)

predictions = model.predict(x_test)
predictions[0]

np.argmax(predictions[0])
keys[2]

#%% [markdown]
#Confusion matrix
from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, predictions)
print(confusion_matrix)
#%%
#%% [markdown]
#f1score
from sklearn.metrics import f1_score
f1_score =f1_score(y_test, predictions, average='macro')
print(f1_score)
#%%